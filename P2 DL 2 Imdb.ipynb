{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x,train_y),(test_x,test_y) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequence(sequences,dimension=10000):\n",
    "    result = np.zeros((len(sequences),dimension))\n",
    "    \n",
    "    for i,sequence in enumerate(sequences):\n",
    "        result[i,sequence]=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize_sequence(train_x)\n",
    "x_test = vectorize_sequence(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_y).astype('float32')\n",
    "y_test = np.asarray(test_y).astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,305\n",
      "Trainable params: 160,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16,input_shape=(10000,),activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 205us/step - loss: 0.1761 - accuracy: 0.7904 - val_loss: 0.1088 - val_accuracy: 0.8794\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 2s 107us/step - loss: 0.0816 - accuracy: 0.9070 - val_loss: 0.0909 - val_accuracy: 0.8830\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 2s 92us/step - loss: 0.0575 - accuracy: 0.9336 - val_loss: 0.0833 - val_accuracy: 0.8884\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 2s 79us/step - loss: 0.0443 - accuracy: 0.9519 - val_loss: 0.0815 - val_accuracy: 0.8896\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 2s 79us/step - loss: 0.0353 - accuracy: 0.9646 - val_loss: 0.0842 - val_accuracy: 0.8870\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 2s 79us/step - loss: 0.0290 - accuracy: 0.9721 - val_loss: 0.0854 - val_accuracy: 0.8864\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0237 - accuracy: 0.9793 - val_loss: 0.0886 - val_accuracy: 0.8818\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0203 - accuracy: 0.9837 - val_loss: 0.0910 - val_accuracy: 0.8780\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0164 - accuracy: 0.9872 - val_loss: 0.0938 - val_accuracy: 0.8746\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 2s 77us/step - loss: 0.0137 - accuracy: 0.9901 - val_loss: 0.0953 - val_accuracy: 0.8764\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0121 - accuracy: 0.9916 - val_loss: 0.0984 - val_accuracy: 0.8726\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0104 - accuracy: 0.9923 - val_loss: 0.1008 - val_accuracy: 0.8704\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0092 - accuracy: 0.9933 - val_loss: 0.1013 - val_accuracy: 0.8714\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0083 - accuracy: 0.9938 - val_loss: 0.1034 - val_accuracy: 0.8692\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0074 - accuracy: 0.9944 - val_loss: 0.1045 - val_accuracy: 0.8674\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 2s 77us/step - loss: 0.0069 - accuracy: 0.9946 - val_loss: 0.1054 - val_accuracy: 0.8684\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0065 - accuracy: 0.9947 - val_loss: 0.1059 - val_accuracy: 0.8712\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 2s 77us/step - loss: 0.0062 - accuracy: 0.9948 - val_loss: 0.1069 - val_accuracy: 0.8686\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 2s 77us/step - loss: 0.0060 - accuracy: 0.9948 - val_loss: 0.1077 - val_accuracy: 0.8680\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 2s 78us/step - loss: 0.0058 - accuracy: 0.9949 - val_loss: 0.1081 - val_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=20,batch_size=512,validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals=[]\n",
    "for i in y_test:\n",
    "    actuals.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=[]\n",
    "for i in y_preds:\n",
    "    if i[0]>0.5:\n",
    "        preds.append(1)\n",
    "    else:\n",
    "        preds.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Actuals':actuals,'Predictions':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actuals</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actuals  Predictions\n",
       "0          0.0            0\n",
       "1          1.0            1\n",
       "2          1.0            0\n",
       "3          0.0            1\n",
       "4          1.0            1\n",
       "...        ...          ...\n",
       "24995      1.0            1\n",
       "24996      1.0            1\n",
       "24997      0.0            0\n",
       "24998      0.0            0\n",
       "24999      0.0            0\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85924\n",
      "0.866781017724414\n",
      "0.84896\n",
      "[[10869  1631]\n",
      " [ 1888 10612]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix\n",
    "\n",
    "print(accuracy_score(actuals,preds))\n",
    "print(precision_score(actuals,preds))\n",
    "print(recall_score(actuals,preds))\n",
    "print(confusion_matrix(actuals,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_token(id_):\n",
    "    for k,v in word_index.items():\n",
    "        if v==id_ - 3:\n",
    "            return k\n",
    "    return '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_review(id_):\n",
    "    review = ' '.join(return_token(i) for i in train_x[id_])\n",
    "    print(review)\n",
    "    \n",
    "    polarity = 'Postive' if train_y[id_] else 'Negative'\n",
    "    print(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "Postive\n"
     ]
    }
   ],
   "source": [
    "return_review(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "return_review(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had ? working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how ? this is to watch save yourself an hour a bit of your life\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "return_review(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
